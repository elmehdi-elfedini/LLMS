{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ce notebook vise à extraire des informations pertinentes à partir de journaux d'oncologie en utilisant le modèle Gemini Pro 1.5."
      ],
      "metadata": {
        "id": "3o10zqWLX5n8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation des bibliothèques nécessaires"
      ],
      "metadata": {
        "id": "Vi0KrjWLdHOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys9i8cYx8JPw",
        "outputId": "c7b75b02-da56-49e3-899f-03505ec5cebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.6/146.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Name: langchain\n",
            "Version: 0.1.13\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, jsonpatch, langchain-community, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: langchain-experimental\n",
            "---\n",
            "Name: langchain-core\n",
            "Version: 0.1.34\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, requests, tenacity\n",
            "Required-by: langchain, langchain-community, langchain-experimental, langchain-google-genai, langchain-text-splitters\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain_experimental langchain_core\n",
        "!pip -q install google-generativeai==0.3.1\n",
        "!pip -q install google-ai-generativelanguage==0.4.0\n",
        "!pip -q install langchain-google-genai\n",
        "!pip -q install \"langchain[docarray]\"\n",
        "!pip show langchain langchain-core\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configuration de l'authentification\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import json\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('gemini')\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "id": "68gp3NGP8WMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Obtenez votre clé ici](https://aistudio.google.com/app/prompts/new_chat?utm_source=agd&utm_medium=referral&utm_campaign=core-cta&utm_content=)"
      ],
      "metadata": {
        "id": "JlNEyoj9T6di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour lister tous les modèles disponibles :"
      ],
      "metadata": {
        "id": "zGGuMdxWUGuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [m for m in genai.list_models()]\n",
        "models"
      ],
      "metadata": {
        "id": "ZW0XvX6q8sVG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42450801-4413-4a10-b72b-82803804265e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       top_p=1.0,\n",
              "       top_k=1),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
              "                    'model that supports tuning.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       top_p=1.0,\n",
              "       top_k=1),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
              "                    'model.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       top_p=1.0,\n",
              "       top_k=1),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description='The best image understanding model to handle a broad range of applications',\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       top_p=1.0,\n",
              "       top_k=1),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description='The best image understanding model to handle a broad range of applications',\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nous avons testé le modèle avec l'observation3\n"
      ],
      "metadata": {
        "id": "b8Ow5NnuVDqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "\n",
        "\n",
        "#Pour la génération du prompt, nous avons utilisé la bibliothèque LangChain\n",
        "prompt_template = \"\"\"\n",
        "\n",
        "  You are a medical expert assistant. Answer the question as detailed as possible  from the provided context, make sure to provide all the details, if the answer is not in\n",
        "  provided context just write 'Not specified', and give me this information in a json format ,don't provide the wrong answer\\n\\n\n",
        "  Context:\\n {context}?\\n\n",
        "  Question: \\n{question}\\n\n",
        "\n",
        "  Answer:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
        "chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "folder_path = \"/content/pdfs\"\n",
        "\n",
        "question = \"Please provide the following information in a JSON format with the specified keys:\\n\\\n",
        "        - Patient:\\n\\\n",
        "          - Âge\\n\\\n",
        "          - Sexe\\n\\\n",
        "          - Lieu\\n\\\n",
        "          - Profession\\n\\\n",
        "          - Téléphone\\n\\\n",
        "        - Antécédents_médicaux:\\n\\\n",
        "          - Personnels:\\n\\\n",
        "            - Médicaux\\n\\\n",
        "            - Chirurgicaux\\n\\\n",
        "          - Familiaux:\\n\\\n",
        "            - Cas_similaires\\n\\\n",
        "          - Statut_hormonal:\\n\\\n",
        "            - Ménopausée\\n\\\n",
        "            - Années_ménopause\\n\\\n",
        "        - Motifs_de_consultation:\\n\\\n",
        "          - Durée\\n\\\n",
        "          - Symptômes\\n\\\n",
        "          - Symptômes_associés\\n\\\n",
        "          - Contexte\\n\\\n",
        "        - Examen_initial:\\n\\\n",
        "          - Examen_gynécologique:\\n\\\n",
        "            - Résultats\\n\\\n",
        "        - Examens_paracliniques:\\n\\\n",
        "          - Type\\n\\\n",
        "          - Date\\n\\\n",
        "          - Lieu\\n\\\n",
        "          - Résultat (or Résultats if multiple results are present)\\n\\\n",
        "        - Orientation\\n\\\n",
        "        - Symptômes_présentés\\n\\\n",
        "        - Examen_physique:\\n\\\n",
        "          - Général:\\n\\\n",
        "            - OMS\\n\\\n",
        "            - Peau\\n\\\n",
        "            - Conjonctive\\n\\\n",
        "          - Abdomen\\n\\\n",
        "          - Examen_pelvien:\\n\\\n",
        "            - Speculum vaginal\\n\\\n",
        "            - Toucher rectal\\n\\\n",
        "          - Ganglions_Lymphatiques_IngUinaux\\n\\\n",
        "        - Résumé:\\n\\\n",
        "          - Description_patient\\n\\\n",
        "          - Évaluation_clinique_et_traitement\"\n",
        "\n",
        "\n",
        "\n",
        "patient_data_list = []\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        clinical_context = loader.load()\n",
        "        print(clinical_context)\n",
        "        response = chain({\"input_documents\": clinical_context, \"question\": question}, return_only_outputs=True)\n",
        "\n",
        "        # pour Supprimez les triples backticks et les caractères de nouvelle ligne\n",
        "        cleaned_json_str = response['output_text'].strip('```json\\n').strip()\n",
        "\n",
        "        json_dict = json.loads(cleaned_json_str)\n",
        "\n",
        "        # Pour Ajouter le nom du PDF au dictionnaire\n",
        "        json_dict[\"file_name\"] = filename\n",
        "\n",
        "        patient_data_list.append(json_dict)\n",
        "\n",
        "        print(f\"Medical information from {filename} added to the list\")\n",
        "        print()\n",
        "\n",
        "\n",
        "with open('patient_data.json', 'w') as json_file:\n",
        "    json.dump(patient_data_list, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(\"Toutes les informations médicales ont été enregistrées dans : patient_data.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oBZmsA-nQ8a",
        "outputId": "d85a99ea-d817-4cd5-c3cc-e9d9fe95f69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content=\"Nom et Prénom :\\nAge: Genre: Etat. Civil: F A AUTRE  44IP:\\nLit:Identification du patient :*1\\xa0287\\xa0485*\\nObservations :JOURNAL DES OBSERVATIONS \\nCLINIQUES\\n    Service:SERVICE DE \\n10/02/2020  00:00:00 Date: YESSOUFOU MOHAMED médecin\\nEXAMEN PROCTOLOGIQUE DU 06/02/2020 normale\\nInspection/\\nABSENCEDEMARIQUE HEMORROIDAIRES\\nPAS DE FISSURE NI DE FISTULE\\nPAS DE PROLAPSUS HEMORROIDAIRE A L'EFFORT NI AU REPOS\\nTOUCHER RECTAL\\nNON DOULOUREUX\\nBONNE TONICITE SPHYNCTERIENNE\\nPAS DE MASSE \\nDOIGTIER REVIENT PROPRE AU RETRAIT\\nAnuscopie/Rectoscopie: progression jusqu'au 15 cm de la MA ; muqueuse macroscopiquement normale\\n++>Simulation ce jourSERVICE DE RADIOTHÉRAPIE service:\\n05/02/2020  00:00:00 Date: YESSOUFOU MOHAMED médecin\\nAvant de simuler la patiente\\n=>>Expliquer a la patiente le déroulement de la rth\\n=>L'existance d'éventuels effet secondaires\\n=>La necessité de ne pas interrompre sa rth\\n=>l'existance d'une surveillance hebdomadaire\\nVu qu'il y a une atteinte de la parois ant du rectum ==>Rectoscopie prévue pour le 06/02/2020\\nAprès avoir fait la rectoscopie présenter la patiente au sénior pour decision de simulerSERVICE DE RADIOTHÉRAPIE service:\\n04/02/2020  00:00:00 Date: YESSOUFOU MOHAMED médecinSERVICE DE RADIOTHÉRAPIE service:\", metadata={'source': '/content/pdfs/observation3.pdf', 'page': 0}), Document(page_content=\"Nom et Prénom :\\nAge: Genre: Etat. Civil: F A AUTRE  44IP:\\nLit:Identification du patient :*1\\xa0287\\xa0485*\\nObservations :JOURNAL DES OBSERVATIONS \\nCLINIQUES\\n    Service:SERVICE DE \\nDr Yessoufou/Dr ELMAHFOUDI\\nPatiente de 44 ANS H et O de Chefchaoun; Ramédiste; Tel 0700370019\\nATCD\\n=>Personnel\\n*Médicaux\\n*Chirurgicaux\\n*G4P4 4 EV\\n=>Familiaux: pas de cas similaires dans la famille\\n=>Statut hormonal: Ménopausé il 05 ans\\nHDM: le début de la symptomatologie remonterait à environ 03 mois par des metrorragies de moy abondance sans \\nsignes digestifs ni urinaire; evoluant dans un contexte de CSE.\\n==>EXAMEN INITIALE EN GOII:Gros col tumoral de 05 cm avec atteintes des pramètres\\n=>EXAMEN PARACLINIQUE REALISE\\n**Anapath de la Biopsie du col  au CHU le 25/10/2019: CE moyennement différencié mature et infiltrant\\n**Echo pelvienne au service le 27/01/2020: gros col hypervascularisé au niveau de la lèvre antérieure; endomètre fin \\nechogène et homogène; les 02 ovaires vues et RAS\\n**TDM TAP du 16/12/2019 au CHU:\\nProcessus tumoral cervico utérin localement avancé envahissant en bas les 2/3 supérieurs du vagin; en \\narrière la parois antérieure du rectum; infiltrant latéralement le paramètre gauche supérieur et perte de \\nliséré graisseux de séparation avec la vessie en avant et ADPs de l'axe iliaque lombo aortique. Absence \\nd'anomalie par ailleurs.\\nC'est ainsi qu'elle nous a été adressé\\nPlaintes:  Douleurs pelviennes\\nEXAMEN Physique:  Patiente OMS 1; tég et conj normocolorés\\nAbdomen souple sans masse pathologique palpable\\nSP+TV: processus tumoral du col utérin d'environ 05 cm avec infiltration du vagin\\nTR: paramètres envahies en bilatérale\\nAires gg inguinales: libres\\nAilleurs: RAS\\nAu total il s'agit d'une patiente de 55 ans sans ATCS pathologiques qui présente un  CE du col utérin \\nclassé IVA\\n=>CAT: \\nBilan biologique + rdv pour simulation\", metadata={'source': '/content/pdfs/observation3.pdf', 'page': 1}), Document(page_content=\"Nom et Prénom :\\nAge: Genre: Etat. Civil: F A AUTRE  44IP:\\nLit:Identification du patient :*1\\xa0287\\xa0485*\\nObservations :JOURNAL DES OBSERVATIONS \\nCLINIQUES\\n    Service:SERVICE DE \\nDate d'impression: 19/02/2020 _12:41\\nELMAHFOUDI Imprimé par:\", metadata={'source': '/content/pdfs/observation3.pdf', 'page': 2})]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medical information from observation3.pdf added to the list\n",
            "\n",
            "Toutes les informations médicales ont été enregistrées dans : patient_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Afficher les résultats"
      ],
      "metadata": {
        "id": "Q5-J7U82sEYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('patient_data.json', 'r') as json_file:\n",
        "    patient_data_list = json.load(json_file)\n",
        "\n",
        "print(json.dumps(patient_data_list, indent=4, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUgnuHJRXUvI",
        "outputId": "c7215a16-0980-49c7-ad7b-7cece06c0d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"Patient\": {\n",
            "            \"Âge\": \"44\",\n",
            "            \"Sexe\": \"F\",\n",
            "            \"Lieu\": \"Chefchaoun\",\n",
            "            \"Profession\": \"Non spécifié\",\n",
            "            \"Téléphone\": \"0700370019\"\n",
            "        },\n",
            "        \"Antécédents_médicaux\": {\n",
            "            \"Personnels\": {\n",
            "                \"Médicaux\": \"Non spécifiés\",\n",
            "                \"Chirurgicaux\": \"Non spécifiés\"\n",
            "            },\n",
            "            \"Familiaux\": {\n",
            "                \"Cas_similaires\": \"Non spécifiés\"\n",
            "            },\n",
            "            \"Statut_hormonal\": {\n",
            "                \"Ménopausée\": \"Oui\",\n",
            "                \"Années_ménopause\": \"5\"\n",
            "            }\n",
            "        },\n",
            "        \"Motifs_de_consultation\": {\n",
            "            \"Durée\": \"Environ 03 mois\",\n",
            "            \"Symptômes\": \"Métro-hémorragies de moyenne abondance\",\n",
            "            \"Symptômes_associés\": \"Aucun\",\n",
            "            \"Contexte\": \"CSE\"\n",
            "        },\n",
            "        \"Examen_initial\": {\n",
            "            \"Examen_gynécologique\": {\n",
            "                \"Résultats\": \"Gros col tumoral de 05 cm avec atteintes des paramètres\"\n",
            "            }\n",
            "        },\n",
            "        \"Examens_paracliniques\": [\n",
            "            {\n",
            "                \"Type\": \"Biopsie du col\",\n",
            "                \"Date\": \"25/10/2019\",\n",
            "                \"Lieu\": \"CHU\",\n",
            "                \"Résultat\": \"CE moyennement différencié mature et infiltrant\"\n",
            "            },\n",
            "            {\n",
            "                \"Type\": \"Écho pelvienne\",\n",
            "                \"Date\": \"27/01/2020\",\n",
            "                \"Lieu\": \"Non spécifié\",\n",
            "                \"Résultat\": \"Gros col hypervascularisé au niveau de la lèvre antérieure; endomètre fin échogène et homogène; les 02 ovaires vues et RAS\"\n",
            "            },\n",
            "            {\n",
            "                \"Type\": \"TDM TAP\",\n",
            "                \"Date\": \"16/12/2019\",\n",
            "                \"Lieu\": \"CHU\",\n",
            "                \"Résultat\": \"Processus tumoral cervico utérin localement avancé envahissant en bas les 2/3 supérieurs du vagin; en arrière la paroi antérieure du rectum; infiltrant latéralement le paramètre gauche supérieur et perte de liséré graisseux de séparation avec la vessie en avant et ADPs de l'axe iliaque lombo aortique. Absence d'anomalie par ailleurs.\"\n",
            "            }\n",
            "        ],\n",
            "        \"Orientation\": \"Simulation\",\n",
            "        \"Symptômes_présentés\": \"Douleurs pelviennes\",\n",
            "        \"Examen_physique\": {\n",
            "            \"Général\": {\n",
            "                \"OMS\": \"1\",\n",
            "                \"Peau\": \"Normocolorée\",\n",
            "                \"Conjonctive\": \"Normocolorée\"\n",
            "            },\n",
            "            \"Abdomen\": \"Souple sans masse pathologique palpable\",\n",
            "            \"Examen_pelvien\": {\n",
            "                \"Speculum vaginal\": \"Processus tumoral du col utérin d'environ 05 cm avec infiltration du vagin\",\n",
            "                \"Toucher rectal\": \"Paramètres envahies en bilatérale\"\n",
            "            },\n",
            "            \"Ganglions_Lymphatiques_IngUinaux\": \"Libres\"\n",
            "        },\n",
            "        \"Résumé\": {\n",
            "            \"Description_patient\": \"Patiente de 44 ans sans ATCS pathologiques\",\n",
            "            \"Évaluation_clinique_et_traitement\": \"CE du col utérin classé IVA\"\n",
            "        },\n",
            "        \"file_name\": \"observation3.pdf\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SoqK2JntXjDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}